{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from xgb_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>unemployment_rate</th>\n",
       "      <th>CPI</th>\n",
       "      <th>treasury_yield</th>\n",
       "      <th>GDP_growth</th>\n",
       "      <th>SP500_return</th>\n",
       "      <th>AZN</th>\n",
       "      <th>BMY</th>\n",
       "      <th>JNJ</th>\n",
       "      <th>LLY</th>\n",
       "      <th>MRK</th>\n",
       "      <th>NVO</th>\n",
       "      <th>NVS</th>\n",
       "      <th>PFE</th>\n",
       "      <th>ROG</th>\n",
       "      <th>inflation_change</th>\n",
       "      <th>unemp_change</th>\n",
       "      <th>treasury_yield_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-02-01</td>\n",
       "      <td>4.1</td>\n",
       "      <td>170.000</td>\n",
       "      <td>6.661000</td>\n",
       "      <td>0.496560</td>\n",
       "      <td>-1.522563</td>\n",
       "      <td>-12.828964</td>\n",
       "      <td>-13.228004</td>\n",
       "      <td>-16.339821</td>\n",
       "      <td>-11.121498</td>\n",
       "      <td>-21.701151</td>\n",
       "      <td>2.220031</td>\n",
       "      <td>3.838386</td>\n",
       "      <td>-11.226228</td>\n",
       "      <td>54.440789</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.141500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>171.000</td>\n",
       "      <td>6.519500</td>\n",
       "      <td>0.511258</td>\n",
       "      <td>9.413333</td>\n",
       "      <td>22.264136</td>\n",
       "      <td>-0.218329</td>\n",
       "      <td>-2.079067</td>\n",
       "      <td>5.804243</td>\n",
       "      <td>0.913712</td>\n",
       "      <td>8.390897</td>\n",
       "      <td>6.420237</td>\n",
       "      <td>14.101954</td>\n",
       "      <td>6.922258</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.141500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-04-01</td>\n",
       "      <td>3.8</td>\n",
       "      <td>170.900</td>\n",
       "      <td>6.256522</td>\n",
       "      <td>1.327803</td>\n",
       "      <td>-3.266805</td>\n",
       "      <td>5.567379</td>\n",
       "      <td>-8.205683</td>\n",
       "      <td>17.437698</td>\n",
       "      <td>23.153694</td>\n",
       "      <td>12.400712</td>\n",
       "      <td>-0.097663</td>\n",
       "      <td>2.559423</td>\n",
       "      <td>15.213674</td>\n",
       "      <td>7.370518</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.262978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-05-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>171.200</td>\n",
       "      <td>5.990526</td>\n",
       "      <td>-0.181797</td>\n",
       "      <td>-1.572223</td>\n",
       "      <td>-0.148357</td>\n",
       "      <td>5.395746</td>\n",
       "      <td>8.484832</td>\n",
       "      <td>-1.296597</td>\n",
       "      <td>7.374072</td>\n",
       "      <td>20.863985</td>\n",
       "      <td>5.169310</td>\n",
       "      <td>5.638019</td>\n",
       "      <td>-8.163265</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.265995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-06-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>172.200</td>\n",
       "      <td>6.440455</td>\n",
       "      <td>0.305565</td>\n",
       "      <td>1.728613</td>\n",
       "      <td>10.549735</td>\n",
       "      <td>5.788826</td>\n",
       "      <td>14.239888</td>\n",
       "      <td>31.641749</td>\n",
       "      <td>3.078671</td>\n",
       "      <td>2.813690</td>\n",
       "      <td>8.474599</td>\n",
       "      <td>8.076012</td>\n",
       "      <td>13.131313</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.449928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>3.4</td>\n",
       "      <td>300.536</td>\n",
       "      <td>3.616190</td>\n",
       "      <td>0.390254</td>\n",
       "      <td>6.776820</td>\n",
       "      <td>-3.584079</td>\n",
       "      <td>0.972908</td>\n",
       "      <td>-7.489384</td>\n",
       "      <td>-5.928822</td>\n",
       "      <td>-2.549213</td>\n",
       "      <td>2.541749</td>\n",
       "      <td>-0.110227</td>\n",
       "      <td>-13.817335</td>\n",
       "      <td>16.968326</td>\n",
       "      <td>1.546</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.274810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>3.6</td>\n",
       "      <td>301.648</td>\n",
       "      <td>3.531500</td>\n",
       "      <td>-0.442183</td>\n",
       "      <td>-2.514271</td>\n",
       "      <td>-0.290649</td>\n",
       "      <td>-4.328217</td>\n",
       "      <td>-6.217115</td>\n",
       "      <td>-9.568502</td>\n",
       "      <td>-1.089288</td>\n",
       "      <td>1.592445</td>\n",
       "      <td>-7.172811</td>\n",
       "      <td>-7.286115</td>\n",
       "      <td>5.451681</td>\n",
       "      <td>1.112</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.084690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>3.5</td>\n",
       "      <td>301.808</td>\n",
       "      <td>3.746842</td>\n",
       "      <td>-0.442183</td>\n",
       "      <td>3.313488</td>\n",
       "      <td>8.035329</td>\n",
       "      <td>0.507544</td>\n",
       "      <td>1.862736</td>\n",
       "      <td>10.703390</td>\n",
       "      <td>0.141189</td>\n",
       "      <td>12.873250</td>\n",
       "      <td>9.367574</td>\n",
       "      <td>0.566924</td>\n",
       "      <td>11.025813</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.215342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>3.4</td>\n",
       "      <td>302.918</td>\n",
       "      <td>3.663043</td>\n",
       "      <td>-0.442183</td>\n",
       "      <td>1.985238</td>\n",
       "      <td>5.489119</td>\n",
       "      <td>-3.664707</td>\n",
       "      <td>5.612908</td>\n",
       "      <td>15.269915</td>\n",
       "      <td>9.289214</td>\n",
       "      <td>5.836894</td>\n",
       "      <td>16.334413</td>\n",
       "      <td>-4.681371</td>\n",
       "      <td>-1.517467</td>\n",
       "      <td>1.110</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.083799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>3.7</td>\n",
       "      <td>304.127</td>\n",
       "      <td>3.460000</td>\n",
       "      <td>-0.442183</td>\n",
       "      <td>0.461619</td>\n",
       "      <td>-0.191204</td>\n",
       "      <td>-2.695194</td>\n",
       "      <td>-5.277949</td>\n",
       "      <td>8.487855</td>\n",
       "      <td>-4.382088</td>\n",
       "      <td>-3.967915</td>\n",
       "      <td>-6.161645</td>\n",
       "      <td>-2.237080</td>\n",
       "      <td>-2.162160</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.203043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  unemployment_rate      CPI  treasury_yield  GDP_growth  \\\n",
       "0    2000-02-01                4.1  170.000        6.661000    0.496560   \n",
       "1    2000-03-01                4.0  171.000        6.519500    0.511258   \n",
       "2    2000-04-01                3.8  170.900        6.256522    1.327803   \n",
       "3    2000-05-01                4.0  171.200        5.990526   -0.181797   \n",
       "4    2000-06-01                4.0  172.200        6.440455    0.305565   \n",
       "..          ...                ...      ...             ...         ...   \n",
       "275  2023-01-01                3.4  300.536        3.616190    0.390254   \n",
       "276  2023-02-01                3.6  301.648        3.531500   -0.442183   \n",
       "277  2023-03-01                3.5  301.808        3.746842   -0.442183   \n",
       "278  2023-04-01                3.4  302.918        3.663043   -0.442183   \n",
       "279  2023-05-01                3.7  304.127        3.460000   -0.442183   \n",
       "\n",
       "     SP500_return        AZN        BMY        JNJ        LLY        MRK  \\\n",
       "0       -1.522563 -12.828964 -13.228004 -16.339821 -11.121498 -21.701151   \n",
       "1        9.413333  22.264136  -0.218329  -2.079067   5.804243   0.913712   \n",
       "2       -3.266805   5.567379  -8.205683  17.437698  23.153694  12.400712   \n",
       "3       -1.572223  -0.148357   5.395746   8.484832  -1.296597   7.374072   \n",
       "4        1.728613  10.549735   5.788826  14.239888  31.641749   3.078671   \n",
       "..            ...        ...        ...        ...        ...        ...   \n",
       "275      6.776820  -3.584079   0.972908  -7.489384  -5.928822  -2.549213   \n",
       "276     -2.514271  -0.290649  -4.328217  -6.217115  -9.568502  -1.089288   \n",
       "277      3.313488   8.035329   0.507544   1.862736  10.703390   0.141189   \n",
       "278      1.985238   5.489119  -3.664707   5.612908  15.269915   9.289214   \n",
       "279      0.461619  -0.191204  -2.695194  -5.277949   8.487855  -4.382088   \n",
       "\n",
       "           NVO        NVS        PFE        ROG  inflation_change  \\\n",
       "0     2.220031   3.838386 -11.226228  54.440789             1.000   \n",
       "1     8.390897   6.420237  14.101954   6.922258             1.000   \n",
       "2    -0.097663   2.559423  15.213674   7.370518            -0.100   \n",
       "3    20.863985   5.169310   5.638019  -8.163265             0.300   \n",
       "4     2.813690   8.474599   8.076012  13.131313             1.000   \n",
       "..         ...        ...        ...        ...               ...   \n",
       "275   2.541749  -0.110227 -13.817335  16.968326             1.546   \n",
       "276   1.592445  -7.172811  -7.286115   5.451681             1.112   \n",
       "277  12.873250   9.367574   0.566924  11.025813             0.160   \n",
       "278   5.836894  16.334413  -4.681371  -1.517467             1.110   \n",
       "279  -3.967915  -6.161645  -2.237080  -2.162160             0.100   \n",
       "\n",
       "     unemp_change  treasury_yield_change  \n",
       "0            -0.1              -0.141500  \n",
       "1            -0.1              -0.141500  \n",
       "2            -0.2              -0.262978  \n",
       "3             0.2              -0.265995  \n",
       "4             0.0               0.449928  \n",
       "..            ...                    ...  \n",
       "275          -0.1              -0.274810  \n",
       "276           0.2              -0.084690  \n",
       "277          -0.1               0.215342  \n",
       "278          -0.1              -0.083799  \n",
       "279           0.3              -0.203043  \n",
       "\n",
       "[280 rows x 18 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('clean_monthly_data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "macros = ['unemployment_rate', 'GDP_growth', 'SP500_return', 'inflation_change', 'unemp_change', 'treasury_yield_change']\n",
    "\n",
    "for m in macros:\n",
    "    data[f'{m}_lag'] = data[m].shift(1)\n",
    "    data[f'{m}_lag2'] = data[m].shift(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Quater_dummy'] = 0\n",
    "data['Quater_rippel'] = 0\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "for index, row in data.iterrows():\n",
    "    if row['Date'].month in [3, 6, 9, 12]:\n",
    "        data.loc[index, 'Quater_dummy'] = 1\n",
    "    if row['Date'].month in [1, 4, 7, 10]:\n",
    "        data.loc[index, 'Quater_dummy'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['NVS', 'AZN', 'BMY', 'JNJ', 'LLY', 'MRK', 'NVO', 'PFE', 'ROG']\n",
    "\n",
    "for t in tickers:\n",
    "    data[f'{t}_lag'] = data[t].shift(1)\n",
    "    data[f'{t}_lag2'] = data[t].shift(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Macros Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_macro = data.copy()\n",
    "to_exclude = []\n",
    "\n",
    "for t in tickers:\n",
    "    to_exclude.append(t)\n",
    "    to_exclude.append(f'{t}_lag')\n",
    "    to_exclude.append(f'{t}_lag2')\n",
    "\n",
    "\n",
    "to_exclude.append('Date')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates1m = ['2022-05-01', '2022-06-01', '2022-07-01', '2022-08-01', '2022-09-01', '2022-10-01', '2022-11-01', '2022-12-01', '2023-01-01', '2023-02-01', '2023-03-01', '2023-04-01']\n",
    "\n",
    "params = {'n_estimators': [100, 150, 200],\n",
    "          'max_depth': [3, 5, 7],\n",
    "          'learning_rate': [0.01, 0.1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVS-1m-loss: 3.2618896020753922\n",
      "AZN-1m-loss: 2.3879767866548227\n",
      "BMY-1m-loss: 3.3772761038209924\n",
      "JNJ-1m-loss: 2.775884336227969\n",
      "LLY-1m-loss: 2.724265567092514\n",
      "MRK-1m-loss: 1.7247076488973418\n",
      "NVO-1m-loss: 2.2703321926043105\n",
      "PFE-1m-loss: 4.4454702710296905\n",
      "ROG-1m-loss: 6.529772320564978\n"
     ]
    }
   ],
   "source": [
    "for t in tickers:\n",
    "    loss = get_model_performance(data_macro, t, 0.05, to_exclude, dates1m, 1, params)\n",
    "    print(f'{t}-1m-loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVS-3m-loss: 7.6856894581403505\n",
      "AZN-3m-loss: 7.913814541466462\n",
      "BMY-3m-loss: 10.320303291058712\n",
      "JNJ-3m-loss: 8.557777771943062\n",
      "LLY-3m-loss: 9.370765301931797\n",
      "MRK-3m-loss: 4.76074037038329\n",
      "NVO-3m-loss: 6.529063424849665\n",
      "PFE-3m-loss: 14.277869771777205\n",
      "ROG-3m-loss: 22.197556289628714\n"
     ]
    }
   ],
   "source": [
    "dates3m = ['2022-05-01', '2022-06-01', '2022-07-01', '2022-08-01', '2022-09-01', '2022-10-01', '2022-11-01', '2022-12-01', '2023-01-01', '2023-02-01']\n",
    "\n",
    "for t in tickers:\n",
    "    loss = get_model_performance(data_macro, t, 0.05, to_exclude, dates3m, 3, params)\n",
    "    print(f'{t}-3m-loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVS-6m-loss: 13.922965018790793\n",
      "AZN-6m-loss: 14.953414871997783\n",
      "BMY-6m-loss: 19.592622280901292\n",
      "JNJ-6m-loss: 16.75052847277061\n",
      "LLY-6m-loss: 17.71223617093269\n",
      "MRK-6m-loss: 7.481201076526001\n",
      "NVO-6m-loss: 11.496488756000781\n",
      "PFE-6m-loss: 29.437149808066383\n",
      "ROG-6m-loss: 57.1847587508464\n"
     ]
    }
   ],
   "source": [
    "dates6m = ['2022-05-01', '2022-06-01', '2022-07-01', '2022-08-01', '2022-09-01', '2022-10-01', '2022-11-01']\n",
    "\n",
    "for t in tickers:\n",
    "    loss = get_model_performance(data_macro, t, 0.05, to_exclude, dates6m, 6, params)\n",
    "    print(f'{t}-6m-loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVS-9m-loss: 23.008403478224373\n",
      "AZN-9m-loss: 24.5686933164365\n",
      "BMY-9m-loss: 30.009063820880193\n",
      "JNJ-9m-loss: 26.82202020808235\n",
      "LLY-9m-loss: 28.328063299648246\n",
      "MRK-9m-loss: 12.057306156432961\n",
      "NVO-9m-loss: 18.67089724702614\n",
      "PFE-9m-loss: 47.23267264501412\n",
      "ROG-9m-loss: 70.91790710996713\n"
     ]
    }
   ],
   "source": [
    "dates9m = ['2022-05-01', '2022-06-01', '2022-07-01', '2022-08-01']\n",
    "\n",
    "for t in tickers:\n",
    "    loss = get_model_performance(data_macro, t, 0.05, to_exclude, dates9m, 9, params)\n",
    "    print(f'{t}-9m-loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVS-12m-loss: 34.7126594865153\n",
      "AZN-12m-loss: 30.705399675387714\n",
      "BMY-12m-loss: 42.87319951579293\n",
      "JNJ-12m-loss: 35.917879442837766\n",
      "LLY-12m-loss: 32.12677166131159\n",
      "MRK-12m-loss: 19.9878014080006\n",
      "NVO-12m-loss: 26.04278140727248\n",
      "PFE-12m-loss: 60.53200796572177\n",
      "ROG-12m-loss: 78.03032275572728\n"
     ]
    }
   ],
   "source": [
    "dates12m = ['2022-05-01']#, '2022-06-01', '2022-07-01', '2022-08-01']\n",
    "\n",
    "for t in tickers:\n",
    "    loss = get_model_performance(data_macro, t, 0.05, to_exclude, dates12m, 12, params)\n",
    "    print(f'{t}-12m-loss: {loss}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Ticker data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stocks = data.copy()\n",
    "to_exclude2 = []\n",
    "\n",
    "for m in macros:\n",
    "    to_exclude2.append(m)\n",
    "    to_exclude2.append(f'{m}_lag')\n",
    "    to_exclude2.append(f'{m}_lag2')\n",
    "\n",
    "for t in tickers:\n",
    "    to_exclude2.append(t)\n",
    "\n",
    "\n",
    "to_exclude2.append('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVS-1m-loss: 3.414639907122538\n",
      "AZN-1m-loss: 2.4748912778635566\n",
      "BMY-1m-loss: 3.218429476513577\n",
      "JNJ-1m-loss: 2.8672552235381374\n",
      "LLY-1m-loss: 2.547822486898083\n",
      "MRK-1m-loss: 2.1477671400466423\n",
      "NVO-1m-loss: 2.253368906513552\n",
      "PFE-1m-loss: 4.295173307153142\n",
      "ROG-1m-loss: 6.658262253019601\n"
     ]
    }
   ],
   "source": [
    "for t in tickers:\n",
    "    loss = get_model_performance(data_stocks, t, 0.05, to_exclude2, dates1m, 1, params)\n",
    "    print(f'{t}-1m-loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVS-3m-loss: 8.396974854419883\n",
      "AZN-3m-loss: 8.347388410096144\n",
      "BMY-3m-loss: 10.381359601222254\n",
      "JNJ-3m-loss: 8.661862897360054\n",
      "LLY-3m-loss: 8.987574628591302\n",
      "MRK-3m-loss: 6.70548003549375\n",
      "NVO-3m-loss: 6.553720027384607\n",
      "PFE-3m-loss: 14.132171488955342\n",
      "ROG-3m-loss: 21.987254376205744\n"
     ]
    }
   ],
   "source": [
    "for t in tickers:\n",
    "    loss = get_model_performance(data_stocks, t, 0.05, to_exclude2, dates3m, 3, params)\n",
    "    print(f'{t}-3m-loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVS-6m-loss: 14.636931830989855\n",
      "AZN-6m-loss: 15.755465305316772\n",
      "BMY-6m-loss: 20.28829824784301\n",
      "JNJ-6m-loss: 16.093740106974575\n",
      "LLY-6m-loss: 16.55997568370876\n",
      "MRK-6m-loss: 12.922695897970929\n",
      "NVO-6m-loss: 10.84030722490124\n",
      "PFE-6m-loss: 26.22467566102721\n",
      "ROG-6m-loss: 54.683840796184356\n"
     ]
    }
   ],
   "source": [
    "for t in tickers:\n",
    "    loss = get_model_performance(data_stocks, t, 0.05, to_exclude2, dates6m, 6, params)\n",
    "    print(f'{t}-6m-loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVS-9m-loss: 25.73808214841266\n",
      "AZN-9m-loss: 25.779581452788236\n",
      "BMY-9m-loss: 30.36335889222024\n",
      "JNJ-9m-loss: 26.27263051583249\n",
      "LLY-9m-loss: 26.405230127405023\n",
      "MRK-9m-loss: 16.15267108443479\n",
      "NVO-9m-loss: 18.23960896578994\n",
      "PFE-9m-loss: 41.662805873575294\n",
      "ROG-9m-loss: 69.35851588018414\n"
     ]
    }
   ],
   "source": [
    "for t in tickers:\n",
    "    loss = get_model_performance(data_stocks, t, 0.05, to_exclude2, dates9m, 9, params)\n",
    "    print(f'{t}-9m-loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVS-12m-loss: 38.28203700916028\n",
      "AZN-12m-loss: 29.775583430299854\n",
      "BMY-12m-loss: 39.48609007062669\n",
      "JNJ-12m-loss: 35.792903991057514\n",
      "LLY-12m-loss: 29.37599455417286\n",
      "MRK-12m-loss: 24.211954757944728\n",
      "NVO-12m-loss: 25.817952858966862\n",
      "PFE-12m-loss: 52.26057140479323\n",
      "ROG-12m-loss: 79.54549250071508\n"
     ]
    }
   ],
   "source": [
    "for t in tickers:\n",
    "    loss = get_model_performance(data_stocks, t, 0.05, to_exclude2, dates12m, 12, params)\n",
    "    print(f'{t}-12m-loss: {loss}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. All Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "covs = data.copy()\n",
    "to_exclude3 = ['Date']\n",
    "\n",
    "for m in macros:\n",
    "    to_exclude3.append(m)\n",
    "\n",
    "for t in tickers:\n",
    "    to_exclude3.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVS-1m-loss: 3.5138862606384227\n",
      "AZN-1m-loss: 2.507503844520777\n",
      "BMY-1m-loss: 3.1283990986378263\n",
      "JNJ-1m-loss: 2.9195623146883727\n",
      "LLY-1m-loss: 2.4998406369522725\n",
      "MRK-1m-loss: 2.054256575208234\n",
      "NVO-1m-loss: 2.189967488495661\n",
      "PFE-1m-loss: 3.8124814432517407\n",
      "ROG-1m-loss: 6.008071505005657\n"
     ]
    }
   ],
   "source": [
    "for t in tickers:\n",
    "    loss = get_model_performance(covs, t, 0.05, to_exclude3, dates1m, 1, params)\n",
    "    print(f'{t}-1m-loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVS-3m-loss: 8.28201080497023\n",
      "AZN-3m-loss: 8.436607694237455\n",
      "BMY-3m-loss: 10.070945306792826\n",
      "JNJ-3m-loss: 8.792779721295421\n",
      "LLY-3m-loss: 8.941899587485693\n",
      "MRK-3m-loss: 6.098034873118603\n",
      "NVO-3m-loss: 6.189802599357888\n",
      "PFE-3m-loss: 13.338469561917984\n",
      "ROG-3m-loss: 20.161326979629717\n"
     ]
    }
   ],
   "source": [
    "for t in tickers:\n",
    "    loss = get_model_performance(covs, t, 0.05, to_exclude3, dates3m, 3, params)\n",
    "    print(f'{t}-3m-loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVS-6m-loss: 14.193649775699447\n",
      "AZN-6m-loss: 16.011103619440654\n",
      "BMY-6m-loss: 19.866049548372136\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tickers:\n\u001b[1;32m----> 2\u001b[0m     loss \u001b[39m=\u001b[39m get_model_performance(covs, t, \u001b[39m0.05\u001b[39;49m, to_exclude3, dates6m, \u001b[39m6\u001b[39;49m, params)\n\u001b[0;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m}\u001b[39;00m\u001b[39m-6m-loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\HP\\Desktop\\Barcelona\\Term3\\Thesis\\BSExNovartis_Thesis\\ModelEvaluation\\xgb_utils.py:152\u001b[0m, in \u001b[0;36mget_model_performance\u001b[1;34m(data, ticker, alpha, exclude, dates, horizon, params, features)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[39m# Perform grid search cross-validation\u001b[39;00m\n\u001b[0;32m    151\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(regressor, param_grid, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mneg_mean_squared_error\u001b[39m\u001b[39m'\u001b[39m, cv\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m--> 152\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m    154\u001b[0m best_regressor \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_estimator_\n\u001b[0;32m    156\u001b[0m y_pred \u001b[39m=\u001b[39m best_regressor\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:538\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resize_state()\n\u001b[0;32m    537\u001b[0m \u001b[39m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m n_stages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stages(\n\u001b[0;32m    539\u001b[0m     X,\n\u001b[0;32m    540\u001b[0m     y,\n\u001b[0;32m    541\u001b[0m     raw_predictions,\n\u001b[0;32m    542\u001b[0m     sample_weight,\n\u001b[0;32m    543\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rng,\n\u001b[0;32m    544\u001b[0m     X_val,\n\u001b[0;32m    545\u001b[0m     y_val,\n\u001b[0;32m    546\u001b[0m     sample_weight_val,\n\u001b[0;32m    547\u001b[0m     begin_at_stage,\n\u001b[0;32m    548\u001b[0m     monitor,\n\u001b[0;32m    549\u001b[0m )\n\u001b[0;32m    551\u001b[0m \u001b[39m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    552\u001b[0m \u001b[39mif\u001b[39;00m n_stages \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:615\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    608\u001b[0m     old_oob_score \u001b[39m=\u001b[39m loss_(\n\u001b[0;32m    609\u001b[0m         y[\u001b[39m~\u001b[39msample_mask],\n\u001b[0;32m    610\u001b[0m         raw_predictions[\u001b[39m~\u001b[39msample_mask],\n\u001b[0;32m    611\u001b[0m         sample_weight[\u001b[39m~\u001b[39msample_mask],\n\u001b[0;32m    612\u001b[0m     )\n\u001b[0;32m    614\u001b[0m \u001b[39m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 615\u001b[0m raw_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stage(\n\u001b[0;32m    616\u001b[0m     i,\n\u001b[0;32m    617\u001b[0m     X,\n\u001b[0;32m    618\u001b[0m     y,\n\u001b[0;32m    619\u001b[0m     raw_predictions,\n\u001b[0;32m    620\u001b[0m     sample_weight,\n\u001b[0;32m    621\u001b[0m     sample_mask,\n\u001b[0;32m    622\u001b[0m     random_state,\n\u001b[0;32m    623\u001b[0m     X_csc,\n\u001b[0;32m    624\u001b[0m     X_csr,\n\u001b[0;32m    625\u001b[0m )\n\u001b[0;32m    627\u001b[0m \u001b[39m# track deviance (= loss)\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[39mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:257\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    254\u001b[0m     sample_weight \u001b[39m=\u001b[39m sample_weight \u001b[39m*\u001b[39m sample_mask\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64)\n\u001b[0;32m    256\u001b[0m X \u001b[39m=\u001b[39m X_csr \u001b[39mif\u001b[39;00m X_csr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m X\n\u001b[1;32m--> 257\u001b[0m tree\u001b[39m.\u001b[39;49mfit(X, residual, sample_weight\u001b[39m=\u001b[39;49msample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    259\u001b[0m \u001b[39m# update tree leaves\u001b[39;00m\n\u001b[0;32m    260\u001b[0m loss\u001b[39m.\u001b[39mupdate_terminal_regions(\n\u001b[0;32m    261\u001b[0m     tree\u001b[39m.\u001b[39mtree_,\n\u001b[0;32m    262\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    269\u001b[0m     k\u001b[39m=\u001b[39mk,\n\u001b[0;32m    270\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\tree\\_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1219\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1247\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   1248\u001b[0m         X,\n\u001b[0;32m   1249\u001b[0m         y,\n\u001b[0;32m   1250\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1251\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m   1252\u001b[0m     )\n\u001b[0;32m   1253\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for t in tickers:\n",
    "    loss = get_model_performance(covs, t, 0.05, to_exclude3, dates6m, 6, params)\n",
    "    print(f'{t}-6m-loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in tickers:\n",
    "    loss = get_model_performance(covs, t, 0.05, to_exclude3, dates9m, 9, params)\n",
    "    print(f'{t}-9m-loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in tickers:\n",
    "    loss = get_model_performance(covs, t, 0.05, to_exclude3, dates12m, 12, params)\n",
    "    print(f'{t}-12m-loss: {loss}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
